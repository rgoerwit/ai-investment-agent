# Multi-Agent Investment Analysis System - Environment Configuration
# Copy this file to .env and fill in your API keys

# =============================================================================
# REQUIRED API KEYS
# =============================================================================

# OpenAI API Key (Required)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Finnhub API Key (Required)
# Get your key from: https://finnhub.io/register
FINNHUB_API_KEY=your_finnhub_api_key_here

# Tavily API Key (Required)
# Get your key from: https://tavily.com/
TAVILY_API_KEY=your_tavily_api_key_here

# FMP - fallback in case Yahoo is missing data
FMP_API_KEY=your_fmp_key_here

# EOHD
EODHD_API_KEY=your_eodhd_key_here

# =============================================================================
# LANGSMITH CONFIGURATION (Optional - for observability and tracing)
# =============================================================================

# LangSmith API Key
# Get your key from: https://smith.langchain.com/
LANGSMITH_API_KEY=your_langsmith_api_key_here

# LangSmith Workspace ID (Required if using org-scoped API key)
# Find your workspace ID in LangSmith Settings â†’ Workspaces
# This should be a UUID, not "default"
LANGSMITH_WORKSPACE_ID=your_workspace_uuid_here

# Enable/disable LangSmith tracing
# Set to false to disable tracing
LANGSMITH_TRACING=true

# LangSmith project name (optional)
LANGSMITH_PROJECT=multi-agent-trading

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# Model to use for quick analysis (faster, less expensive)
QUICK_MODEL=gemini-2.5-flash
# QUICK_MODEL=gemini-2.0-flash-exp # cheaper

# Model to use for deep analysis (more thorough, complex reasoning)
# Default: gemini-3-pro-preview (New release Nov 19, 2025)
DEEP_MODEL=gemini-3-pro-preview

# =============================================================================
# MEMORY SYSTEM CONFIGURATION
# =============================================================================

# Enable persistent learning across analysis runs
# When enabled, agents remember past analyses and improve over time
ENABLE_MEMORY=true

# =============================================================================
# CHROMADB CONFIGURATION
# =============================================================================

# ChromaDB persistence directory (optional)
# CHROMA_PERSIST_DIRECTORY=./chroma_db

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Enable structured JSON logging
STRUCTURED_LOGGING=true

# =============================================================================
# OPTIONAL ADVANCED SETTINGS
# =============================================================================

# OpenAI API base URL (for custom endpoints)
# OPENAI_API_BASE=https://api.openai.com/v1

# Request timeout in seconds
# REQUEST_TIMEOUT=60

# Maximum retries for API calls
# MAX_RETRIES=3

# Rate limiting (requests per minute)
# RATE_LIMIT_RPM=500

# =============================================================================
# NOTES
# =============================================================================
# 
# 1. Never commit the .env file to version control
# 2. Keep your API keys secure and rotate them regularly
# 3. Monitor your API usage to avoid unexpected charges
# 4. LangSmith tracing is optional but highly recommended for debugging
# 5. Use QUICK_MODEL for development/testing to save costs
# 6. ENABLE_MEMORY allows agents to learn from past analyses